var documenterSearchIndex = {"docs":
[{"location":"index.html#ModelOrderReductionToolkit.jl-Models-and-Reductors","page":"Models and Reductors","title":"ModelOrderReductionToolkit.jl Models and Reductors","text":"","category":"section"},{"location":"index.html#Stationary-Models","page":"Models and Reductors","title":"Stationary Models","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A model <: StationaryModel{NOUT} is a map from parameter space to a vector space. When calling model(p, i=1) for i=1,...,NOUT, must return a vector of length output_length(model) and of eltype output_type(model). ","category":"page"},{"location":"index.html#Linear-Model","page":"Models and Reductors","title":"Linear Model","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A model of the form","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A(p) x(p) = b(p)","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"LinearModel","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.LinearModel","page":"Models and Reductors","title":"ModelOrderReductionToolkit.LinearModel","text":"model = LinearModel(Ap::APArray, bp::APArray) <: StationaryModel{1}\nmodel = LinearModel(Ap::APArray, b::AbstractVector) <: StationaryModel{1}\n\nStruct for containing a parameterized linear model A(p) x = b(p) or A(p) x = b with affine parameter  dependence. Can form a solution for a new parameter value by  calling it on a new parameter value x = model(p).\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"For an example, see PoissonModel().","category":"page"},{"location":"index.html#Linear-Matrix-Model","page":"Models and Reductors","title":"Linear Matrix Model","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A model of the form","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A(p) X(p) = B(p)","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"LinearMatrixModel","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.LinearMatrixModel","page":"Models and Reductors","title":"ModelOrderReductionToolkit.LinearMatrixModel","text":"LinearMatrixModel{NOUT}\n\nmodel = LinearMatrixModel(Ap::APArray, bps::AbstractVector{Union{APArray, <:AbstractVector}})\nmodel = LinearMatrixModel(Ap::APArray, Bp::APArray)\nmodel = LinearMatrixModel(Ap::APArray, B::AbstractMatrix)\n\nStruct for containing a parameterized linear model A(p) X = B(p), with affine parameter dependence. Stored internally similarly to a LinearModel, so can solve for a single column of the solution by model(p, i) for i=1,...,NOUT, or can solve for the matrix solution by model(p, 0).\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"For an example, see to_frequency_domain(PenzlModel()).","category":"page"},{"location":"index.html#Stationary-Model-Reductors","page":"Models and Reductors","title":"Stationary Model Reductors","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"Reduced basis methods for stationary models typically require the models to have implemented galerkin_project(model, V[, W=V], r=-1) and galerkin_add!(rom, fom, v, Vold[, w=v, Wold=Vold]).","category":"page"},{"location":"index.html#POD-Reductor","page":"Models and Reductors","title":"POD Reductor","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"Proper orthogonal decomposition which solves the full order model at each parameter value, computes an SVD of the snapshot matrix, and allows for projection onto the resulting left singular vectors.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"PODReductor","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.PODReductor","page":"Models and Reductors","title":"ModelOrderReductionToolkit.PODReductor","text":"pod_reductor <: PODReductor\n\nA struct for holding the parts of a POD reductor for a StationaryModel model. Can access the FOM through  pod_reductor.model, the snapshot matrix through  pod_reductor.snapshots, the singular values through  pod_reductor.S, and the reduced basis  (left singular vectors) through pod_reductor.V.\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"model = PoissonModel()\nparams = [[i,j,k] for i in range(0,1,5) for j in range(0,1,5) for k in range(0,1,5)]\nreductor = PODReductor(model)\nadd_to_rb!(reductor, params) # or add_to_rb!(reductor, snapshots) if snapshot matrix already formed\nrom = form_rom(reductor, 10)","category":"page"},{"location":"index.html#SG-Reductor","page":"Models and Reductors","title":"SG Reductor","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"Strong greedy method which solves the full order model at each parameter value, computes a column-pivoted QR decomposition of the snapshot matrix, and allows for projection onto the resulting orthonormalized snapshots.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"SGReductor","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.SGReductor","page":"Models and Reductors","title":"ModelOrderReductionToolkit.SGReductor","text":"sg_reductor <: SGReductor\n\nA struct for holding the parts of an SG reductor for  a StationaryModel model. Can access the FOM through  sg_reductor.model, the snapshot matrix through  sg_reductor.snapshots, the pivot order through  sg_reductor.p, and the reduced basis through  sg_reductor.V.\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"model = PoissonModel()\nparams = [[i,j,k] for i in range(0,1,5) for j in range(0,1,5) for k in range(0,1,5)]\nreductor = SGReductor(model)\nadd_to_rb!(reductor, params) # or add_to_rb!(reductor, snapshots) if snapshot matrix already formed\nrom = form_rom(reductor, 10)","category":"page"},{"location":"index.html#WG-Reductor","page":"Models and Reductors","title":"WG Reductor","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"Weak greedy method which utilizes an ErrorEstimator to attempt to choose the parameter value (and index) for which the error is the worst for the given RB. Then, forms that full order solution and continues.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"WGReductor","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.WGReductor","page":"Models and Reductors","title":"ModelOrderReductionToolkit.WGReductor","text":"wg_reductor <: WGReductor\n\nStores a FOM in model, an error estimator estimator,  the greedily selected parameters params_greedy, the reduced basis in V, the ROM in rom, the approximate errors at each step in approx_errors, and the truth errors in each step at truth_errors.\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"model = PoissonModel()\nparams = [[i,j,k] for i in range(0,1,5) for j in range(0,1,5) for k in range(0,1,5)]\nestimator = StabilityResidualErrorEstimator(model, params, coercive=true)\nreductor = WGReductor(model, estimator)\nadd_to_rb!(reductor, params, 10)\nrom = form_rom(reductor, 10)","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"See sources 1-3 on more information on successive constraint methods, residual computations, and methodology on weak greedy reduced basis methods.","category":"page"},{"location":"index.html#Nonstationary-Models","page":"Models and Reductors","title":"Nonstationary Models","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A model <: NonstationaryModel is a map from parameter space to a set of ODEs. Calling model(p) initializes the model to the given parameter value. ODE outputs are vector of length output_length(model) and of eltype output_type(model). Can convert into an ODEProblem by to_ode_problem(model[, x0, tspan, p]).","category":"page"},{"location":"index.html#LTI-Model","page":"Models and Reductors","title":"LTI Model","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"A model of the form","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"E(p) x(tp) = A(p) x(tp) + B(p) u(t)\ny(tp) = C(p) x(tp) + D(p) u(t)","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"LTIModel","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.LTIModel","page":"Models and Reductors","title":"ModelOrderReductionToolkit.LTIModel","text":"model = LTIModel(A_in, B_in, C_in, D_in=0, E_in=I) <: NonstationaryModel model = LTIModel(lti<:AbstractStateSpace) <: NonstationaryModel model = LTIModel(lti<:AbstractDescriptorStateSpace) <: NonstationaryModel\n\nStruct for containing a parameterized LTI model E(p) x'(t,p) = A(p) x(t,p) + B(p) u(t) y(t,p) = C(p) x(t,p) + D(p) u(t) with affine parameter dependence where u(t) is some input signal. Can initialize the system to a given  parameter p by calling model(p).\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"Also implements to_ss(model[, p=nothing]) to convert a model to a ControlSystems.jl state space, and to_dss(model[, p=nothing]) to convert to a DescriptorSystems.jl. Also implements to_frequency_domain(model) which returns a LinearMatrixModel to solve for the state variable x in the frequency domain. Also has galerkin_project(model, V[, W=V; r=-1]) implemented for forming reduced order models. To cast to an ODE problem for a given input u(x), call to_ode_problem(model[, x0=0.0, tspan=(0,1), p=nothing, u]).","category":"page"},{"location":"index.html#BT-Reductor","page":"Models and Reductors","title":"BT Reductor","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"The state of the art method for reducing a non-parameterized LTI problem is through balanced truncation. This can be performed with a BTReductor object.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"BTReductor","category":"page"},{"location":"index.html#ModelOrderReductionToolkit.BTReductor","page":"Models and Reductors","title":"ModelOrderReductionToolkit.BTReductor","text":"reductor = BTReductor(model::LTIModel[, p=nothing; noise=1, iterative=nothing, maxdim=-1, lradi_eps=1e-6, dense_row_tol=1e-8])\n\nBalanced truncation reductor object for reducing an LTIModel. If parameter p passed in, model first initialized to parameter value. noise determines amount of printed output. If isnothing(iterative), checks the size and sparsity of the system whether or not to use an iterative method. If iterative==true,  uses an iterative low-rank ADI method to solve for the Gramians (see Kurschner and Benner 2016 Dissertation Alg 4.3), otherwise, uses MatrixEquations.jl to solve them densely. maxdim determines the  maximum rank for the iterative solver, and lradi_eps determines a tolerance for when the algorithm terminantes. If iterative==false, dense_row_tol is used to  truncate the dense Gramians for quicker solving of the RB and HSVs.\n\nThe reachability Gramian can be computed by reductor.R * reductor.R', and the  observability Gramian by reductor.L * reductor.L'.\n\nHSVs stored in reductor.hs.\n\nPetrov-Galerkin test and trial spaces stored in reductor.V and reductor.W respectively.\n\nInitialized-to parameter value stored in reductor.p.\n\n\n\n\n\n","category":"type"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"After forming a BTReductor object on an LTIModel, can obtain the system Gramians through reachability_gramian(reductor) and observability_gramian(reductor). As with other reductors, has form_rom and lift implemented.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"model = PenzlModel()\nreductor = BTReductor(model)\nrom = form_rom(reductor, 20)","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"See source 4 for more information on the iterative method for solving Lyapunov equations used by BTReductor when iterative==true, and see MatrixEquations.jl for the non-sparse Lyapunov solver. See source 5 for the Penzl model example and for more information on truncation of LTI systems.","category":"page"},{"location":"index.html#RB-Reduction","page":"Models and Reductors","title":"RB Reduction","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"For reducing a parameterized LTI problem in a reduced basis setting, one option is to create a (complex) basis in the frequency domain.","category":"page"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"model = ParameterizedPenzlModel()\nfreq_model = to_frequency_domain(model)\nreductor = PODReductor(freq_model)\nparams = [[ω,p1,p2,p3] for ω in range(-500,500,21) for p1 in range(-25,25,6) for p2 in range(-25,25,6) for p3 in range(-25,25,6)]\nreductor = PODReductor(freq_model)\nadd_to_rb!(reductor, params)\nrom = galerkin_project(model, Matrix(reductor.V[:,1:20])) # Faster when converting from VOV to Matrix","category":"page"},{"location":"index.html#References:","page":"Models and Reductors","title":"References:","text":"","category":"section"},{"location":"index.html","page":"Models and Reductors","title":"Models and Reductors","text":"D.B.P. Huynh, G. Rozza, S. Sen, A.T. Patera. A successive constraint linear optimization method for lower bounds of parametric coercivity and inf–sup stability constants. Comptes Rendus Mathematique. Volume 345, Issue 8. 2007. Pages 473-478. https://doi.org/10.1016/j.crma.2007.09.019.\nQuarteroni, Alfio, Andrea Manzoni, and Federico Negri. Reduced Basis Methods for Partial Differential Equations. Vol. 92. UNITEXT. Cham: Springer International Publishing, 2016. http://link.springer.com/10.1007/978-3-319-15431-2.\nYanlai Chen, Jiang Jiahua, and Akil Narayan. A robust error estimator and a residual-free error indicator for reduced basis methods. Computers & Mathematics with Applications. 2019. http://www.sciencedirect.com/science/article/pii/S0898122118306850\nPatrick Kürschner and Peter Benner. Efficient low-rank solutions of large-scale matrix equations. Forschungsberichte aus dem Max-Planck-Institut für Dynamik Komplexer Technischer Systeme. 2016. https://pure.mpg.de/rest/items/item22467967/component/file_2296741/content.\nThilo Penzl. Algorithms for model reduction of large dynamical systems. Linear Algebra and its Applications. Volume 415, Issue 2, Pages 322-343. June 1, 2006. https://www.sciencedirect.com/science/article/pii/S0024379506000371.","category":"page"},{"location":"docs.html#Additional-ModelOrderReductionToolkit.jl-Docstrings","page":"Additional Docstrings","title":"Additional ModelOrderReductionToolkit.jl Docstrings","text":"","category":"section"},{"location":"docs.html#Models","page":"Additional Docstrings","title":"Models","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"galerkin_project\ngalerkin_add!\nPoissonModel\nPenzlModel\nMISOPenzlModel\nto_frequency_domain\nto_ss\nto_dss\nto_ode_problem\nbode\nParameterizedPenzlModel","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.galerkin_project","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.galerkin_project","text":"rom = galerkin_project(model::LinearModel, V[, W=V; r=-1])\n\nPerform (Petrov) Galerkin projection on a linear model where the trial space is the first r columns of V and the test space is the first r columns of W. If r=-1, uses all columns. Returns a new LinearModel.\n\nW' * A(p) * V * x_r = W' * b(p),V * x_r ≈ x = A(p)^(-1) b(p)`\n\n\n\n\n\nrom = galerkin_project(model::LinearMatrixModel, V[, W=V; r=-1])\n\nPerform (Petrov) Galerkin projection on each linear model in model.models.\n\n\n\n\n\ngalerkin_project(model, V[, W=V, ])\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.galerkin_add!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.galerkin_add!","text":"galerkin_add!(rom::LinearModel, fom::LinearModel, v, Vold[, w=v, Wold=Vold; r=-1])\n\nAssuming that rom = galerkin_project(model, Vold, Wold), updates rom such that if V = [Vold v] and W = [Wold w], then rom = galerkin_project(model, V, W).\n\n\n\n\n\ngalerkin_add!(rom::LinearMatrixModel, fom::LinearMatrixModel, v, Vold[, w=v, Wold=Vold; r=-1])\n\nAssuming that rom = galerkin_project(fom, Vold, Wold), updates rom such that if V = [Vold v] and W = [Wold w], then rom = galerkin_project(fom, V, W).\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.PoissonModel","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.PoissonModel","text":"model = PoissonModel([; Nx=999, P=3])\n\nUses finite differences on the following PDE to generate a LinearModel with parameter  dependence. Change discretization with Nx,  and change number of parameters, and hence number of affine terms, with P.\n\n- ∂_x (κ(x, p) ∂_x u(x, p)) = f(x)\n\nu(0,p) = 0; u(1,p) = p[1]\n\nκ(x,p) = (1.05 - (1/2)^(P-1)) + 0.5 p[2] sin(2πx) + 0.25 p[3] sin(4πx) + ... + (1/2)^(P-1) p[P] sin(2π * P * x)\n\nf(x,p) = (0.25 .< x .< 0.75) .* 10.0\n\nlength(p) = P; 0 ≤ p[i] ≤ 1\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.PenzlModel","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.PenzlModel","text":"model = PenzlModel()\n\nGenerates the standard Penzl LTIModel with one input, one output, and ns=1006 dimension state variable.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.MISOPenzlModel","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.MISOPenzlModel","text":"model = MISOPenzlModel()\n\nGenerates an LTIModel with three inputs, one output,  and a state of dimension ns=1006. Same structure as the  Penzl model except the B matrix is changed to\n\n1006×3 Matrix{Float64}:\n 10.0   0.0   0.0\n 10.0   0.0   0.0\n  0.0  10.0   0.0\n  0.0  10.0   0.0\n  0.0   0.0  10.0\n  0.0   0.0  10.0\n  1.0   1.0   1.0\n  ⋮\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n  1.0   1.0   1.0\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.to_frequency_domain","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.to_frequency_domain","text":"frequency_model = to_frequency_domain(model)\n\nAssuming null initial conditions, uses the Laplace transform to convert the LTIModel into a LinearMatrixModel for which the first element of the parameter vector is the imaginary part of the frequency variable. The model is of the form sE(p) X = A(p) X + B(p) where X is the Laplace variable for X and s = 0 + iω\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.to_ss","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.to_ss","text":"to_ss(model[, p=nothing])\n\nInitializes the model to the parameter p if passed in, then returns a ControlSystems.jl StateSpace object. \n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.to_dss","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.to_dss","text":"to_dss(model[, p=nothing])\n\nInitializes the model to the parameter p if passed in, then returns a DescriptorSystems.jl DescriptorStateSpace object. \n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.to_ode_problem","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.to_ode_problem","text":"to_ode_problem(model[, p=nothing; u=(t->zeros(size(model.B, 2))), x0=0.0, tspan=(0,1)])\n\nCreates an ODEProblem for the model <: LTISystem for a given input u(t). Note that this is the ODE for the state variable x. Once have formed the solution object, will have to multiply by model.C to get the output y. Note that DifferentialEquations.jl names the output u, which for this problem is the state variable x, not the input u.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.bode","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.bode","text":"bode(model::LTIModel, ω::Real[, p=nothing])\n\nReturns the transfer function evaluated at s=im*ω, C * (sE - A)^(-1) B + D.\n\n\n\n\n\nbode(model::LTIModel, ωs::Real[, p=nothing])\n\nReturns the transfer function evaluated at s=im*ω for ω in ωs.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.ParameterizedPenzlModel","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.ParameterizedPenzlModel","text":"model = ParameterizedPenzlModel()\n\nGenerates an LTIModel with one input, one output,  and a state of dimension ns=1006. Same structure as the  Penzl model, expect depends on a parameter vector of length 3 which shift the poles along the complex axis. Instantiate to a parameter vector by calling model([p1,p2,p3]).\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Reductors","page":"Additional Docstrings","title":"Reductors","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"StabilityResidualErrorEstimator\nform_rom\nlift\nadd_to_rb!\nget_rom","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.StabilityResidualErrorEstimator","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.StabilityResidualErrorEstimator","text":"StabilityResidualErrorEstimator <: ErrorEstimator\n\nError estimator for a LinearModel which approximates the  stability factor with stability_estimator(p) and computes  the residual norm with residual_norm.\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.form_rom","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.form_rom","text":"form_rom(pod_reductor, r=-1)\n\nPulls the first r left singular vectors from  pod_reductor.decomp, and then Galerkin projects pod_reductor.model onto that basis, and returns the resulting ROM.\n\n\n\n\n\nform_rom(sg_reductor, r=-1)\n\nCalls galerkin_project on the FOM and returns a ROM with RB of dimension r. If r=-1, uses all available columns of sg_reductor.V.\n\n\n\n\n\nform_rom(wg_reductor, r=-1)\n\nCalls galerkin_project on the FOM and returns a ROM with RB of dimension r. If r=-1, uses all available columns of wg_reductor.V.\n\n\n\n\n\nform_rom(bt_reductor[, r=-1])\n\nUses Petrov-Galerkin on the model to form a ROM of order r (largest possible if r==-1). Also, initializes it to bt_reductor.p if not nothing.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.lift","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.lift","text":"lift(pod_reductor, x_r)\n\nGiven a vector solution x_r to a ROM formed by the pod_reductor, which is of smaller dimension than outputs of the FOM, lifts the solution to the same dimension of the FOM. \n\n\n\n\n\nlift(sg_reductor, x_r)\n\nGiven a vector solution x_r to a ROM formed by the sg_reductor, which is of smaller dimension than outputs of the FOM, lifts the solution to the same dimension of the FOM. \n\n\n\n\n\nlift(wg_reductor, x_r)\n\nGiven a vector solution x_r to a ROM formed by the wg_reductor, which is of smaller dimension than outputs of the FOM, lifts the solution to the same dimension of the FOM. \n\n\n\n\n\nlift(bt_reductor, x_r)\n\nGiven a vector solution x_r to a ROM formed by the pod_reductor, which is of smaller dimension than outputs of the FOM, lifts the solution to the same dimension of the FOM. \n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.add_to_rb!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.add_to_rb!","text":"add_to_rb!(pod_reductor, snapshots[; noise=1])\n\nDirectly updates pod_reductor with new snapshots given in the columns of the matrix snapshots.\n\n\n\n\n\nadd_to_rb!(pod_reductor, parameters[; noise=1, progress=true])\n\nLoops through the vector of parameters, forms their full order solutions, adds them to pod_reductor.snapshots, and then updates the singular values  and singular vectors in pod_reductor.S and pod_reductor.V.\n\n\n\n\n\nadd_to_rb!(sg_reductor, snapshots[; noise=1])\n\nDirectly updates sg_reductor with new snapshots given in the columns of the matrix snapshots.\n\n\n\n\n\nadd_to_rb!(sg_reductor, parameters[; noise=1, progress=true])\n\nLoops through the vector of parameters, forms their full order solutions, adds them to sg_reductor.snapshots, and then updates the reduced basis in sg_reductor.V.\n\n\n\n\n\nadd_to_rb!(wg_reductor, params[; noise=1, eps=0.0, zero_tol=1e-15])\n\nLoops through the vector of parameters params, computes the approximate estimator for each, selects the one with the highest error, and updates wg_reductor with  the corresponding full order solution. Returns true if a vector is added to the RB, false otherwise.\n\n\n\n\n\nadd_to_rb!(wg_reductor, params, r[; noise=1, eps=0.0, zero_tol=1e-15])\n\nAdds to wg_reductor at least r times by calling  add_to_rb!(wg_reductor, params, noise=noise, eps=eps, zero_tol=zero_tol) several times. If all r are added, returns true, otherwise false.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.get_rom","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.get_rom","text":"get_rom(wg_reductor)\n\nHelper method for getting the ROM from the  wg_reductor object. Can otherwise obtain it through wg_reductor.rom.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Affinely-parameter-dependent-arrays:","page":"Additional Docstrings","title":"Affinely parameter-dependent arrays:","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"APArray\nformArray!\neim","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.APArray","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.APArray","text":"AffineParametrizedArray(arrays, makeθi[, precompθ=false])\n\nStruct for containing an affine parametrized array A(p) of the form A(p) = ∑ makeθi(p,i) * arrays[i].\n\nArrays are stored in the vector arrays for quick recomputation for new parameter values. Each must be of the same size and dimension so that they can be  broadcast summed.\n\nIf precompθ set to false (default):\n\nThe function makeθi(p,i) takes in a parameter object first, and second an index i=1,...,length(arrays), and returns a scalar\n\nIf precompθ set to true:\n\nThe function makeθi(p) takes in a parameter object, and returns a vector of each of the affine terms.\n\nGiven aparr <: AffineParametrizedArray, and a new parameter value p,  can form the full array A(p) by calling aparr(p).\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.formArray!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.formArray!","text":"formArray!(aparr, arr, p)\n\nGiven an array arr with the same dimensions as the arrays in the APArray aparr, form A(p) and place its values in arr.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.eim","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.eim","text":"eim(arrFun, param_disc[, ϵ=1e-2; maxM=100, noise=1])\n\nMethod for constructing an APArray object from a non-affinely parameter dependent matrix arrFun(p) by empirical interpolation. \n\nparam_disc must be a matrix with columns as parameter vectors, or a vector with elements as parameters.\n\nLoops over the given parameter discretization until a maximum ∞-norm error  of ϵ is achieved over the entire discretization, or until the maximum number of parameter values are chosen, given by maxM.\n\nnoise dictates the amount of printed output. Set 0 for no output, 1 for some output, ≥2 for most.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Matrices-as-vector-of-vectors:","page":"Additional Docstrings","title":"Matrices as vector of vectors:","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"VOV\naddRow!\nremoveRow!\naddCol!\nremoveCol!","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.VOV","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.VOV","text":"VectorOfVectors{T} <: AbstractMatrix{T}\n\nType for defining matrices as vectors of vectors for  quick insertion of rows and columns. Stores the columns as vectors in vecs and its size in size.\n\nConstruct an empty VOV of dimensions (nrows × ncols) where  one of nrows or ncols must be zero:\n\nVectorOfVectors(nrows=0, ncols=0, T=Float64)\n\nConstruct a VOV from a Julia vector of vectors:\n\nVectorOfVectors(vecs::AbstractVector{<:AbstractVector{T}})\n\nConstruct a VOV from a matrix:\n\nVectorOfVectors(M::AbstractMatrix{T})\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.addRow!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.addRow!","text":"addRow!(vov::VectorOfVectors)\n\nAdd a row to the vector of vectors by appending zero(T) to each vector.\n\n\n\n\n\naddRow!(vov::VectorOfVectors, row::AbstractVector)\n\nAdd the vector row to the last column of vov.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.removeRow!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.removeRow!","text":"removeRow!(vov::VectorOfVectors)\n\nRemove a row from the vector of vectors.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.addCol!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.addCol!","text":"addCol!(vov::VectorOfVectors)\n\nAdd a column to the vector of vectors by appending zeros(T,nrow) to vov.vecs.\n\n\n\n\n\naddCol!(vov::VectorOfVectors, col::AbstractVector)\n\nAdd the vector row to the last column of vov.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.removeCol!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.removeCol!","text":"removeCol!(vov::VectorOfVectors)\n\nRemove a column from the vector of vectors.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Successive-constraint-method-(SCM):","page":"Additional Docstrings","title":"Successive constraint method (SCM):","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"ModelOrderReductionToolkit.SCM_Init\ninitialize_SCM_SPD\ninitialize_SCM_Noncoercive\nfind_sigma_bounds","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.SCM_Init","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.SCM_Init","text":"SCM_Init is a struct for holding all of the variables and methods necessary for running the successive constraint method on an affinely-parameter-dependent matrix A(p) = ∑_{i=1}^QA θ_i(p) A_i to compute a lower-bound approximation to the minimum singular value of A.\n\nIt is additionally a functor as calling scm_init(p) on a parameter vector p will return the lower-bound estimate of the minimum singular value of A(p).\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.initialize_SCM_SPD","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.initialize_SCM_SPD","text":"initialize_SCM_SPD(param_disc,Ap,Mα,Mp,ϵ[;optimizer=Tulip.Optimizer,kmaxiter=1000,noise=1,lp_attrs]) = SCM_Init\n\nMethod to initialize an SCM_Init object to perform the SCM on an affinely-parameter-dependent symmetric positive definite matrix Ap<:APArray to compute a lower-bound approximation to the minimum  singular value (stability factor) of A(p).\n\nParameters:\n\nparam_disc: Either a matrix where each column is a parameter value in the discretization, or a vector of parameter vectors.\n\nAp: APArray object that stores the affine parameter dependence of the matrix A(p) = ∑ makeθAi(p,i) Ais[i]\n\nMα: Stability constraint constant (a positive integer)\n\nMp: Positivity constraint constant (a positive integer)\n\nϵ: Relative difference allowed between upper-bound and lower-bound approximation on the parameter discretization (between 0 and 1)\n\nkmaxiter: Maximum number of iterations used in iterating eigensolver before defaulting to full-dense eigensolve.\n\nnoise: Determines amount of printed information, between 0 and 2 with 0 being nothing displayed; default 1.\n\nlp_attrs: A dicitonary of attributes to set for the linear program with the given optimizer.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.initialize_SCM_Noncoercive","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.initialize_SCM_Noncoercive","text":"initialize_SCM_Noncoercive(param_disc,Ap,Mα,Mp,ϵ[;optimizer=Tulip.Optimizer,kmaxiter=1000,noise=1,lp_attrs]) = SCM_Init\n\nMethod to initialize an SCM_Init object to perform the SCM on an affinely-parameter-dependent matrix A(p) = ∑ makeθAi(p,i) Ais[i] to compute a lower-bound approximation to the minimum singular value (stability factor) of A(p).\n\nParameters:\n\nparam_disc: Either a matrix where each column is a parameter value in the discretization, or a vector of parameter vectors.\n\nAp: APArray object to hold information for affine  parameter dependence of matrix A(p). \n\nMα: Stability constraint constant (a positive integer)\n\nMp: Positivity constraint constant (a positive integer)\n\nϵ: Relative difference allowed between upper-bound and lower-bound approximation on the parameter discretization (between 0 and 1)\n\nkmaxiter: Maximum number of iterations used in iterating eigensolver before defaulting to full-dense eigensolve.\n\nnoise: Determines amount of printed information, between 0 and 2 with 0 being nothing displayed; default 1.\n\nlp_attrs: A dicitonary of attributes to set for the linear program with the given optimizer.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.find_sigma_bounds","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.find_sigma_bounds","text":"find_sigma_bounds(scm_init, p[, sigma_eps=1.0; noise=0])\n\nMethod that performs the online phase of SCM for the matrix A(p) = ∑ makeθAi(p,i) Ais[i] to compute lower and upper-bound approximations to the minimum singular value of A. Additional optional parameter sigma_eps such that if the computed ϵ difference of (σ_UB - σ_LB) / σ_UB is less than sigma_eps,  we know that not enough stability constraints were enforced, and  the minimum singular value is directly computed, appended to the  scm_init's upper-bound set, and returned as both the lower and upper-bounds.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Radial-basis-interpolatory-stability-factor","page":"Additional Docstrings","title":"Radial-basis interpolatory stability factor","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"ModelOrderReductionToolkit.Sigma_Min_RBF\nmin_sigma_rbf\nupdate_sigma_rbf!","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.Sigma_Min_RBF","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.Sigma_Min_RBF","text":"Sigma_Min_RBF\n\nA mutable struct used for approximating the minimum singular value of a matrix  with parametric dependence A(p). Given  a new parameter value p, approximate σ_min(A(p)) with sigma_min_rbf(p).\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.min_sigma_rbf","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.min_sigma_rbf","text":"min_sigma_rbf(params, Ais, makeθAi[, ϕ=gaussian_rbf])\n\nMethod to form a interpolatory radial-basis function functor to approximate the minimum singular value of a parametrized matrix A(p). Pass as input either a matrix params where each column is a parameter vector, or a vector  of vectors params where each vector is a parameter. \n\nOptional argument for the radial-basis function ϕ, which defaults to the Gaussian ϕ(r) = exp(-r^2).\n\nReturns a functor sigma_min_rbf <: Sigma_Min_RBF such that given a new parameter vector p, sigma_min_rbf(p) returns an approximation to the minimum singular value of A(p).\n\nOffline, solves for the minimum singular value for each parameter in params, and uses this to form an interpolatory approximation in the form of log(σ_min(A(p))) ≈ ω_0 + ∑ (ω_i p_i) + ∑ (γ_i ϕ(p - p_i)) where p_i is the i'th parameter in params, and ω_0, ω_i, and γ_i are determined by the given params such that the approximation holds true for all p_i, and that ∑ γ_i = 0, and that ∑ γ_i p_i[j] = 0 for each j.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.update_sigma_rbf!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.update_sigma_rbf!","text":"update_sigma_rbf!(sigma_min_rbf, ϕ)\n\nGiven a Sigma_Min_RBF object sigma_min_rbf, update its RBF, ϕ, and update the coefficients.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#Computation-of-norm-of-residual","page":"Additional Docstrings","title":"Computation of norm of residual","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"ModelOrderReductionToolkit.ResidualNormComputer\nModelOrderReductionToolkit.StandardResidualNormComputer\nModelOrderReductionToolkit.ProjectionResidualNormComputer","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.ResidualNormComputer","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.ResidualNormComputer","text":"res <: ResidualNormComputer{T}\n\nAbstract type for computing the norm of the residual for weak greedy RB methods. Must implement the update!(res, v) and compute(res, u_r, p) methods.\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.StandardResidualNormComputer","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.StandardResidualNormComputer","text":"StandardResidualNormComputer{T} <: ResidualNormComputer{T} StandardResidualNormComputer(Ap::APArray,bp::APArray,V=nothing,X=nothing)\n\nA struct for containing the necessary vectors and matrices for quickly compute the X-norm of the residual, r(u_r,p) = A(p) (u - V u_r) = b(p) - A(p) V u_r, by taking advantage of affine parameter dependence of A(p) and b(p).\n\nHere, u solves A(p) u = b(p) with A and b having affine parameter dependence, and V is a matrix with columns defining bases for approximation spaces u ≈ V u_r.\n\n\n\n\n\n","category":"type"},{"location":"docs.html#ModelOrderReductionToolkit.ProjectionResidualNormComputer","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.ProjectionResidualNormComputer","text":"ProjectionResidualNormComputer{T} <: ResidualNormComputer{T} ProjectionResidualNormComputer(Ap::APArray,bp::APArray,V=nothing,X=nothing)\n\nA struct for containing the necessary vectors and matrices for quickly compute the X-norm of the residual, r(u_r,p) = A(p) (u - V u_r) = b(p) - A(p) V u_r, by taking advantage of affine parameter dependence of A(p) and b(p). Uses a projection method which is more stable than the standard method.\n\nHere, u solves A(p) u = b(p) with A and b having affine parameter dependence, and V is a matrix with columns defining bases for approximation spaces u ≈ V u_r.\n\n\n\n\n\n","category":"type"},{"location":"docs.html#Linear-algebra-utilities","page":"Additional Docstrings","title":"Linear algebra utilities","text":"","category":"section"},{"location":"docs.html","page":"Additional Docstrings","title":"Additional Docstrings","text":"ModelOrderReductionToolkit.full_lu\nModelOrderReductionToolkit.smallest_real_eigval\nModelOrderReductionToolkit.largest_real_eigval\nModelOrderReductionToolkit.smallest_real_pos_eigpair\nModelOrderReductionToolkit.smallest_sval\nModelOrderReductionToolkit.orthonormalize_mgs2!","category":"page"},{"location":"docs.html#ModelOrderReductionToolkit.full_lu","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.full_lu","text":"full_lu(A; steps=-1)\n\nPerforms a completely pivoted LU factorization on the matrix A, returning permutation vectors Q and P, and lower and upper triangular matrices L and U, such that if all steps are performed, then A[P,Q] = L*U.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.smallest_real_eigval","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.smallest_real_eigval","text":"smallest_real_eigval(A, kmaxiter[, noise=1, krylovsteps=10])\n\nGiven a hermitian matrix A, attempts to compute the  most negative (real) eigenvalue. First, uses Krylov iteration with a shift-invert procedure with Gershgorin disks, and if  not successful, calls a full, dense, eigensolve.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.largest_real_eigval","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.largest_real_eigval","text":"largest_real_eigval(A, kmaxiter[, noise=1])\n\nGiven a hermitian matrix A, attempts to compute the  most positive (real) eigenvalue. First, uses Krylov iteration with no shift-invert, and if not successful, calls a full,  dense, eigensolve.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.smallest_real_pos_eigpair","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.smallest_real_pos_eigpair","text":"smallest_real_pos_eigpair(A, kmaxiter[, noise=1])\n\nGiven a hermitian, positive definite matrix A, attempts to compute the  smallest (real) eigenvalue and eigenvector. First, uses Krylov iteration with shift-invert around zero, and if not successful, calls a full,  dense, eigensolve. Returns a tuple with the first component being the  eigenvalue, and the second component being the eigenvector.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.smallest_sval","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.smallest_sval","text":"smallest_sval(A, kmaxiter[, noise=1])\n\nGiven a matrix A, attempts to compute the smallest singular value of it by Krylov iteration and inversion around 0. If unsuccessful, computes a full, dense svd.\n\n\n\n\n\n","category":"function"},{"location":"docs.html#ModelOrderReductionToolkit.orthonormalize_mgs2!","page":"Additional Docstrings","title":"ModelOrderReductionToolkit.orthonormalize_mgs2!","text":"orthonormalize_mgs2!(u, V)\n\nGiven a matrix V, and a new vector u, orthogonalize u  with respect to the columns of V, and computes its norm nu. If nu != 0, divides u by nu and returns  nu. If nu == 0, then u lives in the span of V, and 0 is returned.\n\n\n\n\n\n","category":"function"},{"location":"rbm_tutorial.html#Reduced-Basis-Method-Tutorial","page":"RBM Tutorial","title":"Reduced Basis Method Tutorial","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"This tutorial follows closely to the book Reduced Basis Methods for Partial Differential Equations by Quateroni, Alfie, Manzoni, and Negri. For more information, see their text, source 2.","category":"page"},{"location":"rbm_tutorial.html#Problem-formulation-and-motivation","page":"RBM Tutorial","title":"Problem formulation and motivation","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"In this tutorial, we consider scalar, linear, elliptic, parametrized PDEs of the form","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"mathcalL(u(xp)p) = f(xp)","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"where p is some parameter (vector), and the solution u depends on a spatial variable x and the parameter. We are interested in such problems specifically as upon discretization, say with finite elements, the discrete problem can be written in the form","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"A(p) u(p) = b(p)","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"where A(p)inmathbbR^Ntimes N, u(p)inmathbbR^N, and b(p)inmathbbR^N. Additionally, we will assume affine parameter dependence, i.e., we can write A(p) as ","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"A(p) = sum_i=1^QA theta_i^A(p) A_i","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"and b(p) as","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"b(p) = sum_i=1^Qb theta_i^b(p) b_i","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Note that if a problem does not match this form, there exist algorithms ((D)EIM) to convert the problem to this form.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Upon sufficient discretization, we expect N to be large, and thus the problem of inverting A(p) several times for different parameter values can be expensive. A model order reduction technique is to build a reduced basis (RB) approximation to the solution. To do this, we wish to build an appropriate r dimensional RB space, with r ll N, on wish to use Galerkin projection. ","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Specifically, given linearly independent (assumed orthogonal) basis vectors to this space, v_i_i=1^r, we construct the RB space matrix","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"V = beginbmatrix         v_1  v_2  cdots  v_r           endbmatrix in mathbbR^N times r","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"such that the problem can be approximated by","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"V^T A(p) V u_r(p) = V^T bquad u(p) approx V u_r(p)","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"where now the task is to invert the much smaller, rtimes r matrix, V^T A(p) V to form u_r(p), and then the solution is approximated by V u_r(p). Additionally, due to the affine parameter dependence of A(p), we need not store any terms that depend on N, rather we only need to store the matrices V^T A_i V in mathbbR^rtimes r for i=1ldotsQA.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, suppose we wished to solve an inverse problem, such as finding the parameter vector p^* that yields some some 'optimal' solution u^*(p). Or suppose that we wish to perform a sensitivity analysis of u(p) on several different parameter values p. These tasks would typically require us to solve the full-order problem a large number of times which may be computationally expensive. ","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"If we are willing to spend offline time to generate an RB space, V, with dimension rll N, then we can much more efficiently spend time online computing the Galerkin projected solution, V u_r(p), at a fraction of a cost of computing the full-order solution.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We will consider a steady state heat equation for this tutorial with affine-parameter dependent spacial diffusion coefficient and forcing terms. Once discretized, it can be written in the form A(p) u = b(p) with A(p) and b(p) each with affine parameter dependence. This model can be instantiated in ModelOrderReductionToolkit.jl by calling PoissonModel().","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"using ModelOrderReductionToolkit\nmodel = PoissonModel()","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We can then form a snapshot matrix over a set of P=125 parameter vectors.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"params = [[i,j,k] for i in range(0,1,5) for j in range(0,1,5) for k in range(0,1,5)]\nP = length(params)\n\nS = zeros(output_length(model), P)\nfor i in 1:P\n    p = params[i]\n    u = model(p)\n    S[:,i] .= u\nend\n\nS","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Let's visualize the solutions.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"using Plots\nplt = plot()\nfor i in 1:P\n    plot!(S[:,i],label=false,alpha=0.25)\nend\ntitle!(\"Solution Set\")\nsavefig(plt, \"rbm_tut1.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html#Proper-Orthogonal-Decomposition/Principal-Component-Analysis","page":"RBM Tutorial","title":"Proper Orthogonal Decomposition/Principal Component Analysis","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We know from the Schmidt-Eckart-Young theorem that the r-dimensional linear subspace that captures the most \"energy\" from the solutions in S (per the Frobenius norm) is the one spanned by the first r left singular vectors of S. More specifically, if we denote VinmathbbR^Ntimes r to be the matrix whose r columns are the first r left singular vectors of S, and let sigma_1geqsigma_2geqldotsgeqsigma_N be the singular values of S, then we can write that","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"S - VV^TS_F = min_textrank(B)leq r A - B_F = sqrtsum_i=r+1^N sigma_i^2","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"where VV^TS is the projection of S onto the columns of V.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We can explicitly compute the SVD and pull the first r columns as ","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"using LinearAlgebra\nr = 5\nU,s,_ = svd(S)\nV = U[:,1:r]\nnothing; # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We can also plot the exponential singular value decay, suggesting to us that such an RBM will perform well.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"plt = plot(s, yaxis=:log, label=false)\nyaxis!(\"Singular Values\")\nxaxis!(\"Dimension\")\nsavefig(plt, \"rbm_tut2.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, the Schmidt-Eckart-Young theorem tells us that this basis is optimal in the sense that it minimizes l^2 error in directly projecting our solutions, i.e., performing u(p) approx VV^Tu(p). Let's visualize the accuracy of these projections.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"plt = plot()\ncolors = palette(:tab10)\nidxs = [rand(1:P) for i in 1:6]\nfor i in 1:6\n    idx = idxs[i]\n    p = params[idx]\n    plot!(S[:,idx], c=colors[i], label=false)\n    u_approx = V * V' * S[:,idx]\n    plot!(u_approx, c=colors[i], label=false, ls=:dash)\nend\ntitle!(\"Truth and projected POD solutions\")\nsavefig(plt, \"rbm_tut3.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"However, we wished to create a reduced order model (ROM) such that given any new parameter value, we can quickly reproduce a new solution. As was noted before, we do this through a Galerkin projection","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"V^T A(p) V u_r(p) = V^T b implies u(p) approx V u_r(p) = u_textapprox(p)","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"from which we require only inverting an rtimes r matrix. Although this is no longer guaranteed \"optimal\" by the Schmidt-Eckart-Young theorem, let's see how this performs on the same snapshots. To perform this task in ModelOrderReductionToolkit.jl, we pass the snapshot matrix into a PODReductor object and form a ROM from the reductor.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"pod_reductor = PODReductor(model)\nadd_to_rb!(pod_reductor, S)\npod_rom = form_rom(pod_reductor, r)\nplt = plot()\ncolors = palette(:tab10)\nfor i in 1:6\n    idx = idxs[i]\n    p = params[idx]\n    plot!(S[:,idx], c=colors[i], label=false)\n    u_r = pod_rom(p)\n    u_approx = lift(pod_reductor, u_r)\n    plot!(u_approx, c=colors[i], label=false, ls=:dash)\nend\ntitle!(\"Truth and projected Galerkin POD solutions\")\nsavefig(plt, \"rbm_tut4.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"As we can see from these plots, a 5-dimensional approximation is quite accurate here! Even though after discretization, these solutions lie in mathbbR^999, we have shown that the solution manifold lies approximately on a 5-dimensional space. Additionally, even though we were only guaranteed \"optimality\" from direct projection of solutions, we still have very good accuracy when we use a Galerkin projection on the problem.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"This process of projection onto left singular values is typically called Proper Orthogonal Decomposition (POD). Note that forming a PODReductor will call svd on the snapshot matrix. We can access the singular values from pod_reductor.S, and the left-singular vectors from pod_reductor.V (note that left-singular vectors are usually denoted with U, but we use V to stick with RB notation).","category":"page"},{"location":"rbm_tutorial.html#Strong-Greedy-Algorithm","page":"RBM Tutorial","title":"Strong Greedy Algorithm","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"An alternative way to generate this reduced basis is through a process called the strong greedy algorithm. This algorithm is called greedy, because we iteratively choose basis elements in a greedy way. We begin by choosing v_1 to be the column of our solution matrix, S with the largest norm, and then normalized it by its length","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"s_1^* = max_i s_iquad v_1 = fracs_1^*s_1^*","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, we use a Gram-Schmidt procedure to orthogonalize all other columns of S with respect to v_1:","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"s_i^(1) = s_i - (v_1^T s_i) v_1quad i=1ldotsP","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"After the j-1'st element v_j-1 is chosen and all of the orthogonalization is performed, we then choose v_j to be the column of S^(j-1) which has the largest norm, i.e., has the worst projection error:","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"s_j^* = max_i s_i^(j-1)quad v_j = fracs_j^*s_j^*","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"and again orthogonalize","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"s_i^(j) = s_i^(j-1) - (v_j^T s_i^(j-1)) v_jquad i=1ldotsP","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Note that this procedure is exactly like performing a pivoted QR factorization on the matrix S. Let's form this reduced basis of the same dimension:","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Q,_,_ = qr(S, LinearAlgebra.ColumnNorm())\nV = Q[:,1:r]\nnothing; # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, we will play the same game. First, we directly project the solutions onto this space","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"plt = plot()\nfor i in 1:6\n    idx = idxs[i]\n    p = params[idx]\n    plot!(S[:,idx], c=colors[i], label=false)\n    u_approx = V * V' * S[:,idx]\n    plot!(u_approx, c=colors[i], label=false, ls=:dash)\nend\ntitle!(\"Truth and projected SG solutions\")\nsavefig(plt, \"rbm_tut5.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, we will use an SGReductor object to form a Galerkin-projected reduced order model.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"sg_reductor = SGReductor(model)\nadd_to_rb!(sg_reductor, S)\nsg_rom = form_rom(sg_reductor, r)\nplt = plot()\nfor i in 1:6\n    idx = idxs[i]\n    p = params[idx]\n    plot!(S[:,idx], c=colors[i], label=false)\n    u_r = sg_rom(p)\n    u_approx = lift(sg_reductor, u_r)\n    plot!(u_approx, c=colors[i], label=false, ls=:dash)\nend\ntitle!(\"Truth and projected Galerkin SG solutions\")\nsavefig(plt, \"rbm_tut6.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"This procedure also performs quite well. We may expect the POD algorithm to be a bit more accurate/general as it can choose basis elements that are not \"in the columns\" of S. Similar to the PODReductor object, we can access the reduced basis from sg_reductor.V.","category":"page"},{"location":"rbm_tutorial.html#Weak-Greedy-Algorithm","page":"RBM Tutorial","title":"Weak Greedy Algorithm","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Now, one downside of the above procedures was that we needed the matrix of full-order solutions ahead of time to perform either the SVD or QR factorizations. If our model was very computationally expensive, we would not want to have to do this. This is where the weak greedy algorithm is useful. It is again a greedy algorithm as we will be choosing \"columns\" greedily, but we wish to not have to construct all columns directly.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Suppose now, instead of having access to the columns s_i which correspond to the full-order solutions u(p_i), we only have access to the parameter values p_i. Generally, we would wish to have an a priori error estimator for a Galerkin-projected ROM such that we could loop over our parameter vectors and choose the one with the estimated maximum error. In this tutorial, we use a stability-residual approach","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"One can show that there exists an upper-bound on projection error, given by","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"u(p) - V u_r(p) = A(p)^-1 b(p) - V u_r(p) leq fracb(p) - A(p) V u_r(p)sigma_min(A(p))","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"where sigma_min(A(p)) is the minimum singular value of A(p). Note that this upperbound on the error does not depend on the full order solution, u(p). So, we loop through each parameter vector p_i, and select the one, p^* that yields the highest upper-bound error. We then form the full-order solution u(p_i), normalize it, and append it as a column of V. Note that unlike in the strong algorithm, since we are not using true error, we are not guaranteed to choose the next \"best\" column of V. However, if we are computing a reduced basis of size r, then we only need to call the full-order model r times.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We now need a method to approximate (a lowerbound of ) sigma_min(A(p)), and then the numerator of the above can be computed explicitly. One way of doing this is through the successive constraint method (SCM). This method takes advantage of the affine parameter dependence of A(p), see source 1. We will form an SCM object and initialize an object to compute the norm of the residual through a StabilityResidualErrorEstimator.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"error_estimator = StabilityResidualErrorEstimator(model, params);","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Note that this method assumes that the model is coercive, i.e., the matrix A(p) is symmetric positive definite for each parameter. For this model, we know that this is the case if the parameter vectors have entries between 0 and 1. For a noncoercive model, add the keyword argument coercive=false. With this in place, we have enough to construct the weak greedy reductor.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"wg_reductor = WGReductor(model, error_estimator)","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Note that we have to build the reduced basis by looping over a parameter set, we will do this by calling add_to_rb!. Afterwards, since the reductor must store the ROM at each step to make error approximations, we can simply pull it from the reductor object.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"add_to_rb!(wg_reductor, params, r)\nprintln(\" \") # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"wg_rom = wg_reductor.rom","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We can access the greedily chosen reduced basis by calling (note that for computational purposes, V is stored as a VectorOfVectors object).","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"wg_reductor.V","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"We can now visualize these solutions by calling wg_rom(p) on a paramater vector p.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"plt = plot()\nfor i in 1:6\n    idx = idxs[i]\n    p = params[idx]\n    plot!(S[:,idx], c=colors[i], label=false)\n    u_r = wg_rom(p)\n    u_approx = lift(wg_reductor, u_r)\n    plot!(u_approx, c=colors[i], label=false, ls=:dash)\nend\ntitle!(\"Truth and WG solutions\")\nsavefig(plt, \"rbm_tut7.svg\"); nothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"(Image: )","category":"page"},{"location":"rbm_tutorial.html#Comparison-of-the-methods","page":"RBM Tutorial","title":"Comparison of the methods","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Let's compare the above algorithms by comparing their average and worst case accuracy over the parameter set.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"errors = [Float64[] for _ in 1:3]\nfor (i,p) in enumerate(params)\n    pod_error = norm(lift(pod_reductor, pod_rom(p)) .- S[:,i])\n    push!(errors[1], pod_error)\n    sg_error = norm(lift(sg_reductor, sg_rom(p)) .- S[:,i])\n    push!(errors[2], sg_error)\n    wg_error = norm(lift(wg_reductor, wg_rom(p)) .- S[:,i])\n    push!(errors[3], wg_error)\nend\nprintln(\"Errors for RB dimension r=$r\")\nprintln(\"POD mean error: $(sum(errors[1]) / length(errors[1]))\")\nprintln(\"POD worst error: $(maximum(errors[1]))\")\nprintln(\"SG mean error: $(sum(errors[2]) / length(errors[2]))\")\nprintln(\"SG worst error: $(maximum(errors[2]))\")\nprintln(\"WG mean error: $(sum(errors[3]) / length(errors[3]))\")\nprintln(\"WG worst error: $(maximum(errors[3]))\")\nnothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"Let's repeat the process for a reduced basis of dimension r=15 Let's compare the above algorithms by comparing their average and worst case accuracy over the parameter set.","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"oldr = r\nr = 15\npod_rom = form_rom(pod_reductor, r)\nsg_rom = form_rom(sg_reductor, r)\nadd_to_rb!(wg_reductor, params, r - oldr)\nwg_rom = wg_reductor.rom\nerrors = [Float64[] for _ in 1:3]\nfor (i,p) in enumerate(params)\n    pod_error = norm(lift(pod_reductor, pod_rom(p)) .- S[:,i])\n    push!(errors[1], pod_error)\n    sg_error = norm(lift(sg_reductor, sg_rom(p)) .- S[:,i])\n    push!(errors[2], sg_error)\n    wg_error = norm(lift(wg_reductor, wg_rom(p)) .- S[:,i])\n    push!(errors[3], wg_error)\nend\nprintln(\"Errors for RB dimension r=$r\")\nprintln(\"POD mean error: $(sum(errors[1]) / length(errors[1]))\")\nprintln(\"POD worst error: $(maximum(errors[1]))\")\nprintln(\"SG mean error: $(sum(errors[2]) / length(errors[2]))\")\nprintln(\"SG worst error: $(maximum(errors[2]))\")\nprintln(\"WG mean error: $(sum(errors[3]) / length(errors[3]))\")\nprintln(\"WG worst error: $(maximum(errors[3]))\")\nnothing # hide","category":"page"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"In conclusion, the weak greedy algorithm takes advantage of the affine parameter dependence of A(p) and b(p), and uses an upper-bound error approximator to produce a reduced basis that approximates solutions with comparable error compared to the strong greedy algorithm and the POD algorithm without needing to compute all solutions ahead of time.","category":"page"},{"location":"rbm_tutorial.html#References:","page":"RBM Tutorial","title":"References:","text":"","category":"section"},{"location":"rbm_tutorial.html","page":"RBM Tutorial","title":"RBM Tutorial","text":"D.B.P. Huynh, G. Rozza, S. Sen, A.T. Patera. A successive constraint linear optimization method for lower bounds of parametric coercivity and inf–sup stability constants. Comptes Rendus Mathematique. Volume 345, Issue 8. 2007. Pages 473-478. https://doi.org/10.1016/j.crma.2007.09.019.\nQuarteroni, Alfio, Andrea Manzoni, and Federico Negri. Reduced Basis Methods for Partial Differential Equations. Vol. 92. UNITEXT. Cham: Springer International Publishing, 2016. http://link.springer.com/10.1007/978-3-319-15431-2.","category":"page"}]
}
